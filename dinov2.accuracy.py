# -*- coding: utf-8 -*-
"""DINOv2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WbDdSRLd2fzIFYnRcpD0Rx_THVx6qcBK

This script extracts feature embeddings from the DINOv2 model
for a cartoon image dataset. It uses pretrained DINOv2-base
model from Hugging Face to generate image features, which can then
be used for downstream tasks such as classification.

Dataset paths:
- RGB images
- Mask images

Outputs:
- Feature tensors (X_rgb, X_mask)
- Corresponding labels (y_rgb, y_mask)
"""

!pip install torch torchvision transformers scikit-learn

from google.colab import drive
drive.mount('/content/drive')

from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from transformers import AutoImageProcessor, AutoModel
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
import torch

# Paths
rgb_path = "/content/drive/MyDrive/carton/RGB"
mask_path = "/content/drive/MyDrive/carton/mask"

# Use GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

from torchvision import transforms

# Convert any image to RGB
class ConvertToRGB:
    def __call__(self, img):
        return img.convert("RGB")

# Ensure images are converted to RGB format and resized to 224x224 to match ViT input
transform = transforms.Compose([
    ConvertToRGB(),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

# Load pretrained DINOv2-base image processor and model from Hugging Face
processor = AutoImageProcessor.from_pretrained("facebook/dinov2-base")
model = AutoModel.from_pretrained("facebook/dinov2-base").to(device)
model.eval()  # Set model to evaluation mode

from tqdm import tqdm

# Function to extract CLS token embeddings from DINOv2 model for all images in a DataLoader
def extract_features(data_loader):
    features = []
    labels = []

    with torch.no_grad():     # Disable gradient calculations for inference
        for images, lbls in tqdm(data_loader):  # ⬅️ track progress
            inputs = processor(images=list(images), return_tensors="pt", do_rescale=False).to(device)
            outputs = model(**inputs)
            cls_tokens = outputs.last_hidden_state[:, 0, :]    # CLS token embeddings
            features.append(cls_tokens.cpu())
            labels.append(lbls)

    return torch.cat(features), torch.cat(labels)

from collections import Counter
print("RGB Class distribution:", Counter(y_rgb.numpy()))
print("Mask Class distribution:", Counter(y_mask.numpy()))

# RGB
rgb_dataset = datasets.ImageFolder(rgb_path, transform=transform)
rgb_loader = DataLoader(rgb_dataset, batch_size=32, shuffle=False)
X_rgb, y_rgb = extract_features(rgb_loader)

# Mask
mask_dataset = datasets.ImageFolder(mask_path, transform=transform)
mask_loader = DataLoader(mask_dataset, batch_size=32, shuffle=False)
X_mask, y_mask = extract_features(mask_loader)

print("RGB:", len(rgb_dataset))
print("Mask:", len(mask_dataset))

# Standardizes DINOv2 RGB features so that each feature dimension has mean = 0 and standard deviation = 1
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_rgb_np = X_rgb.numpy()
X_rgb_scaled = scaler.fit_transform(X_rgb_np)

import numpy as np
from sklearn.preprocessing import LabelEncoder

# Encode labels to consecutive integers starting at 0
encoder = LabelEncoder()
y_rgb_mapped = torch.tensor(encoder.fit_transform(y_rgb.numpy()))
y_mask_mapped = torch.tensor(encoder.fit_transform(y_mask.numpy()))

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Define function to train and evaluate logistic regression classifier
def evaluate_logreg(X, y, name=""):

    # Split data into train and test sets (50% each), stratified by label
    X_train, X_test, y_train, y_test = train_test_split(X.numpy(), y.numpy(), test_size=0.5, stratify=y.numpy(), random_state=42)

    # Standardize training and testing data separately
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Train logistic regression
    clf = LogisticRegression(max_iter=1000)
    clf.fit(X_train_scaled, y_train)

    # Predict and compute accuracy
    y_pred = clf.predict(X_test_scaled)
    acc = accuracy_score(y_test, y_pred)
    print(f"{name} Accuracy (Logistic Regression): {acc * 100:.2f}%")

# Run evaluations on both datasets
evaluate_logreg(X_rgb, y_rgb_mapped, "RGB")
evaluate_logreg(X_mask, y_mask_mapped, "Mask")

# Calculate weighted average accuracy based on dataset sizes
rgb_acc = 98.73
rgb_n = 2937
mask_acc = 89.51
mask_n = 781

total_acc = (rgb_acc * rgb_n + mask_acc * mask_n) / (rgb_n + mask_n)
print(f"Total Weighted Accuracy: {total_acc:.2f}%")