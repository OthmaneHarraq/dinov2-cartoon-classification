# -*- coding: utf-8 -*-
"""DINOv2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WbDdSRLd2fzIFYnRcpD0Rx_THVx6qcBK
"""

!pip install torch torchvision transformers scikit-learn

from google.colab import drive
drive.mount('/content/drive')

from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from transformers import AutoImageProcessor, AutoModel
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
import torch

# Paths
rgb_path = "/content/drive/MyDrive/carton/RGB"
mask_path = "/content/drive/MyDrive/carton/mask"

# Use GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

from torchvision import transforms

# Convert any image to RGB
class ConvertToRGB:
    def __call__(self, img):
        return img.convert("RGB")

transform = transforms.Compose([
    ConvertToRGB(),                        # ensures image is RGB
    transforms.Resize((224, 224)),         # match ViT input size
    transforms.ToTensor(),                 # normalize to [0, 1]
])

# Import DINOv2
processor = AutoImageProcessor.from_pretrained("facebook/dinov2-base")
model = AutoModel.from_pretrained("facebook/dinov2-base").to(device)
model.eval()

from tqdm import tqdm

def extract_features(data_loader):
    features = []
    labels = []

    with torch.no_grad():
        for images, lbls in tqdm(data_loader):  # ⬅️ track progress
            inputs = processor(images=list(images), return_tensors="pt", do_rescale=False).to(device)
            outputs = model(**inputs)
            cls_tokens = outputs.last_hidden_state[:, 0, :]
            features.append(cls_tokens.cpu())
            labels.append(lbls)

    return torch.cat(features), torch.cat(labels)

from collections import Counter
print("RGB Class distribution:", Counter(y_rgb.numpy()))
print("Mask Class distribution:", Counter(y_mask.numpy()))

# RGB
rgb_dataset = datasets.ImageFolder(rgb_path, transform=transform)
rgb_loader = DataLoader(rgb_dataset, batch_size=32, shuffle=False)
X_rgb, y_rgb = extract_features(rgb_loader)

# Mask
mask_dataset = datasets.ImageFolder(mask_path, transform=transform)
mask_loader = DataLoader(mask_dataset, batch_size=32, shuffle=False)
X_mask, y_mask = extract_features(mask_loader)

print("RGB:", len(rgb_dataset))
print("Mask:", len(mask_dataset))

# Standardizes DINOv2 RGB features so that each feature dimension has a mean of 0 and standard deviation of 1
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_rgb_np = X_rgb.numpy()
X_rgb_scaled = scaler.fit_transform(X_rgb_np)

import numpy as np

# Reindex labels to start at 0 and go up by 1
from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()
y_rgb_mapped = torch.tensor(encoder.fit_transform(y_rgb.numpy()))
y_mask_mapped = torch.tensor(encoder.fit_transform(y_mask.numpy()))

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

def evaluate_logreg(X, y, name=""):
    X_train, X_test, y_train, y_test = train_test_split(X.numpy(), y.numpy(), test_size=0.5, stratify=y.numpy(), random_state=42)

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    clf = LogisticRegression(max_iter=1000)
    clf.fit(X_train_scaled, y_train)
    y_pred = clf.predict(X_test_scaled)

    acc = accuracy_score(y_test, y_pred)
    print(f"{name} Accuracy (Logistic Regression): {acc * 100:.2f}%")

evaluate_logreg(X_rgb, y_rgb_mapped, "RGB")
evaluate_logreg(X_mask, y_mask_mapped, "Mask")

rgb_acc = 98.73
rgb_n = 2937
mask_acc = 89.51
mask_n = 781

total_acc = (rgb_acc * rgb_n + mask_acc * mask_n) / (rgb_n + mask_n)
print(f"Total Weighted Accuracy: {total_acc:.2f}%")